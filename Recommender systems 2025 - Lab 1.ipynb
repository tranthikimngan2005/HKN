{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae044c1",
   "metadata": {},
   "source": [
    "# Hệ khuyến nghị. IUH 2025.\n",
    "### Ngày 21/8/2025. Lab 1.\n",
    "Mục tiêu: ôn tập về các tính các khoảng cách / độ tương đồng giữa các vector, cách xây dựng một hệ khuyến nghị cơ bản."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7db8c5-1979-4334-8c2a-c8dd8b2d2821",
   "metadata": {},
   "source": [
    "**Problem 1.**\n",
    "\n",
    "The data includes four users $A$, $B$, $C$, and $D$, who have rated three movies. The ratings are stored in the following lists, and each list contains two numbers indicating the rating of each movie:\n",
    "\n",
    "- Ratings by $A$ are $[4.0; 3.0; 5.0]$.\n",
    "- Ratings by $B$ are $[2.0; 4.0; 3.0]$.\n",
    "- Ratings by $C$ are $[2.0; 4.0; 1.0]$.\n",
    "- Ratings by $D$ are $[4.0; 5.0; 2.0]$.\n",
    "\n",
    "a) Using Euclid distance, Mahattan distance between all pairs among these users then give some remarks on which pairs is closet in each case.\n",
    "\n",
    "b) Create the matrix of Pearson similiary of these rating vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ae2210-a277-496d-862f-81c28ed2dd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "    Movie1  Movie2  Movie3\n",
      "A     4.0     3.0     5.0\n",
      "B     2.0     4.0     3.0\n",
      "C     2.0     4.0     1.0\n",
      "D     4.0     5.0     2.0 \n",
      "\n",
      "Euclidean distance matrix:\n",
      "        A      B      C      D\n",
      "A  0.000  3.000  4.583  3.606\n",
      "B  3.000  0.000  2.000  2.449\n",
      "C  4.583  2.000  0.000  2.449\n",
      "D  3.606  2.449  2.449  0.000 \n",
      "\n",
      "Manhattan distance matrix:\n",
      "      A    B    C    D\n",
      "A  0.0  5.0  7.0  5.0\n",
      "B  5.0  0.0  2.0  4.0\n",
      "C  7.0  2.0  0.0  4.0\n",
      "D  5.0  4.0  4.0  0.0 \n",
      "\n",
      "Pearson similarity matrix:\n",
      "        A      B      C      D\n",
      "A  1.000 -0.500 -0.982 -0.982\n",
      "B -0.500  1.000  0.655  0.327\n",
      "C -0.982  0.655  1.000  0.929\n",
      "D -0.982  0.327  0.929  1.000 \n",
      "\n",
      "Cặp gần nhất (Euclidean): [('B', 'C'), ('C', 'B')]\n",
      "Cặp gần nhất (Manhattan): [('B', 'C'), ('C', 'B')]\n",
      "Cặp tương đồng cao nhất (Pearson): [('A', 'A'), ('B', 'B')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Ratings của các user\n",
    "ratings = {\n",
    "    'A': [4.0, 3.0, 5.0],\n",
    "    'B': [2.0, 4.0, 3.0],\n",
    "    'C': [2.0, 4.0, 1.0],\n",
    "    'D': [4.0, 5.0, 2.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings, index=['Movie1', 'Movie2', 'Movie3']).T\n",
    "print(\"Ratings:\\n\", df, \"\\n\")\n",
    "\n",
    "users = df.index\n",
    "n = len(users)\n",
    "\n",
    "# --- a) Euclidean và Manhattan ---\n",
    "euclid = pd.DataFrame(np.zeros((n, n)), index=users, columns=users)\n",
    "manhattan = pd.DataFrame(np.zeros((n, n)), index=users, columns=users)\n",
    "\n",
    "for i in users:\n",
    "    for j in users:\n",
    "        euclid.loc[i, j] = euclidean(df.loc[i], df.loc[j])\n",
    "        manhattan.loc[i, j] = cityblock(df.loc[i], df.loc[j])\n",
    "\n",
    "print(\"Euclidean distance matrix:\\n\", euclid.round(3), \"\\n\")\n",
    "print(\"Manhattan distance matrix:\\n\", manhattan.round(3), \"\\n\")\n",
    "\n",
    "# --- b) Pearson similarity ---\n",
    "pearson = pd.DataFrame(np.zeros((n, n)), index=users, columns=users)\n",
    "\n",
    "for i in users:\n",
    "    for j in users:\n",
    "        r, _ = pearsonr(df.loc[i], df.loc[j])\n",
    "        pearson.loc[i, j] = r\n",
    "\n",
    "print(\"Pearson similarity matrix:\\n\", pearson.round(3), \"\\n\")\n",
    "\n",
    "# --- Nhận xét cặp gần nhất ---\n",
    "min_euclid = euclid.replace(0, np.nan).min().min()\n",
    "min_manhattan = manhattan.replace(0, np.nan).min().min()\n",
    "max_pearson = pearson.replace(1, np.nan).max().max()\n",
    "\n",
    "closest_euclid = [(i, j) for i in users for j in users if 0 < euclid.loc[i, j] == min_euclid]\n",
    "closest_manhattan = [(i, j) for i in users for j in users if 0 < manhattan.loc[i, j] == min_manhattan]\n",
    "closest_pearson = [(i, j) for i in users for j in users if pearson.loc[i, j] == max_pearson]\n",
    "\n",
    "print(f\"Cặp gần nhất (Euclidean): {closest_euclid}\")\n",
    "print(f\"Cặp gần nhất (Manhattan): {closest_manhattan}\")\n",
    "print(f\"Cặp tương đồng cao nhất (Pearson): {closest_pearson}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15716b82-3497-489d-a97f-e7f509c38df8",
   "metadata": {},
   "source": [
    "**Problem 2.** Vấn đề cold-start, khuyến nghị theo xu hướng cho người dùng mới, sử dụng thông tin rating cao và số lượt rating với một trọng số hợp lý.\n",
    "\n",
    "The dataset files contain metadata for all 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017. This dataset captures feature points like cast, crew, plot keywords, budget, revenue, posters, release dates, languages, production companies, countries, TMDB vote counts, and vote averages. These feature points could be potentially used to train your models for content and collaborative filtering. This dataset consists of the following files:\n",
    "\n",
    "- *movies_metadata.csv*: This file contains information on ~45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, genre, revenue, release dates, languages, production countries, and companies.\n",
    "- *keywords.csv*: Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object.\n",
    "- *credits.csv*: Consists of Cast and Crew Information for all the movies. Available in the form of a stringified JSON Object.\n",
    "- *links.csv*: This file contains the TMDB and IMDB IDs of all the movies featured in the Full MovieLens dataset.\n",
    "- *links_small.csv*: Contains the TMDB and IMDB IDs of a small subset of 9,000 movies of the Full Dataset.\n",
    "- *ratings_small.csv*: The subset of 100,000 ratings from 700 users on 9,000 movies.\n",
    "\n",
    "The Full MovieLens Dataset comprises of 26 million ratings and 750,000 tag applications, from 270,000 users on all the 45,000 movies in this dataset. It can be accessed from the official GroupLens website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cd2a2-6f16-43ea-be78-86bf7e3f417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Movies Metadata\n",
    "metadata = pd.read_csv('movies.csv', low_memory=False)\n",
    "\n",
    "# Print the first three rows\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70dbe9-1cfe-489d-a1d3-b77be393f0d4",
   "metadata": {},
   "source": [
    "One of the most basic metrics you can think of is the ranking to decide which top 250 movies are based on their respective ratings. However, using a rating as a metric has a few caveats:\n",
    "\n",
    "- For one, it does not take into consideration the popularity of a movie. Therefore, a movie with a rating of 9 from 10 voters will be considered 'better' than a movie with a rating of 8.9 from 10,000 voters. For example, imagine you want to order Chinese food, you have a couple of options, one restaurant has a 5-star rating by only 5 people while the other restaurant has 4.5 ratings by 1000 people. Which restaurant would you prefer? The second one, right? Of course, there could be an exception that the first restaurant opened just a few days ago; hence, fewer people voted for it while, on the contrary, the second restaurant is operational for a year.\n",
    "- On a related note, this metric will also tend to favor movies with a smaller number of voters with skewed and/or extremely high ratings. As the number of voters increases, the rating of a movie regularizes and approaches towards a value that is reflective of the movie's quality and gives the user a much better idea as to which movie he/she should choose. While it is difficult to discern the quality of a movie with extremely few voters, you might have to consider external sources to conclude.\n",
    "\n",
    "Taking these shortcomings into consideration, you must come up with a weighted rating that takes into account the average rating and the number of votes it has accumulated. Such a system will make sure that a movie with a 9 rating from 100,000 voters gets a (far) higher score than a movie with the same rating but a mere few hundred voters. Since you are trying to build a clone of IMDB's Top 250, let's use its weighted rating formula as a metric/score. Mathematically, it is represented as follows:\n",
    "\n",
    "$$\\text Weighted Rating (\\bf WR) = \\left({{\\bf v} \\over {\\bf v} + {\\bf m}} \\cdot R\\right) + \\left({{\\bf m} \\over {\\bf v} + {\\bf m}} \\cdot C\\right) $$\n",
    "\n",
    "In the above equation,\n",
    "\n",
    "- v is the number of votes for the movie;\n",
    "- m is the minimum votes required to be listed in the chart;\n",
    "- R is the average rating of the movie;\n",
    "- C is the mean vote across the whole report.\n",
    "\n",
    "You already have the values to v (*vote_count*) and R (*vote_average*) for each movie in the dataset. It is also possible to directly calculate C from this data.Determining an appropriate value for m is a hyperparameter that you can choose accordingly since there is no right value for m. You can consider it as a preliminary negative filter that will simply remove the movies which have a number of votes less than a certain threshold m. The selectivity of your filter is up to your discretion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49788efb-90bb-41a6-81a7-1fe0609e68c4",
   "metadata": {},
   "source": [
    "In this exercise, you will use cutoff $m$ as the 90th percentile. In other words, for a movie to be featured in the charts, it must have more votes than at least 90% of the movies on the list. (On the other hand, if you had chosen the 75th percentile, you would have considered the top 25% of the movies in terms of the number of votes garnered. As percentile decreases, the number of movies considered will increase).\n",
    "\n",
    "As a first step, let's calculate the value of C, the mean rating across all movies using the pandas .mean() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a65cd-e4ce-406e-aa01-c23adbbfc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of vote average column\n",
    "C = metadata['vote_average'].mean()\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debdb13-30a7-4d02-9517-5ee162fa8f35",
   "metadata": {},
   "source": [
    "Next, let's calculate the number of votes, $m$, received by a movie in the 90th percentile. The pandas library makes this task extremely trivial using the .quantile() method of pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8736745-3ffa-4402-a381-59f399b172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum number of votes required to be in the chart, m\n",
    "m = metadata['vote_count'].quantile(0.90)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fe7ca-c779-4cec-b59c-8ba340f941ce",
   "metadata": {},
   "source": [
    "Since now you have the m you can simply use a greater than equal to condition to filter out movies having greater than equal to 160 vote counts: You can use the .copy() method to ensure that the new q_movies DataFrame created is independent of your original metadata DataFrame. In other words, any changes made to the q_movies DataFrame will not affect the original metadata data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ab786-a0d3-4e38-9438-57f17478232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all qualified movies into a new DataFrame\n",
    "q_movies = metadata.copy().loc[metadata['vote_count'] >= m]\n",
    "q_movies.shape\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d055de-ad50-42b7-986d-91d96acb0188",
   "metadata": {},
   "source": [
    "From the above output, it is clear that there are around 10% movies with vote count more than 160 and qualify to be on this list. Next and the most important step is to calculate the weighted rating for each qualified movie. To do this, you will:\n",
    "\n",
    "- Define a function, weighted_rating();\n",
    "- Since you already have calculated m and C you will simply pass them as an argument to the function;\n",
    "- Then you will select the vote_count(v) and vote_average(R) column from the q_movies data frame;\n",
    "- Finally, you will compute the weighted average and return the result.\n",
    "  \n",
    "You will define a new feature score, of which you'll calculate the value by applying this function to your DataFrame of qualified movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb94cf3-6dc0-442b-a497-68a741a3a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes the weighted rating of each movie\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v / (v + m)) * R + (m / (v + m)) * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89991622-3902-4ad9-a336-98322dc727ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad67933-2aa9-41c4-a075-6320234aff4e",
   "metadata": {},
   "source": [
    "Finally, let's sort the DataFrame in descending order based on the score feature column and output the title, vote count, vote average, and weighted rating (score) of the top 20 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540aa90-2770-40c9-ac04-318856ca13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort movies based on score calculated above\n",
    "q_movies = q_movies.sort_values('score', ascending=False)\n",
    "\n",
    "#Print the top 15 movies\n",
    "q_movies[['title', 'vote_count', 'vote_average', 'score']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d39f0-73fc-4d41-b496-9d5fdd817e9e",
   "metadata": {},
   "source": [
    "Well, from the above output, you can see that the simple recommender did a great job!\n",
    "\n",
    "Since the chart has a lot of movies in common with the IMDB Top 250 chart: for example, your top two movies, \"Shawshank Redemption\" and \"The Godfather\", are the same as IMDB and we all know they are indeed amazing movies, in fact, all top 20 movies do deserve to be in that list, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d09e29-acdd-4dbd-9eee-a4fa56f0a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc7cde-7ee2-4806-b030-c53e649fee1a",
   "metadata": {},
   "source": [
    "**Problem 3. Finding all pairs of movies** Trong bài này, ta sẽ tìm tất cả các cặp phim hoặc tất cả các hoán vị của các cặp phim đã được cùng một người xem, từ đó có thể khuyến nghị được.\n",
    "\n",
    "The *user_ratings_df* has been loaded once again containing users, and the movies they have seen.\n",
    "\n",
    "You will need to first create a function that finds all possible pairs of items in a list it is applied to. For ease of use, you will output the values of this as a DataFrame. Since you only want to find movies that have been seen by the same person and not all possible permutations, you will group by *user_id* when applying the function.\n",
    "\n",
    "**Hint.** Create a function called *find_movie_pairs* that finds all permutations of a Series, and stores the results as a DataFrame. \n",
    "Apply this function to the* user_ratings_d*f DataFrame and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fe7d6-aa2f-4d50-815b-40a08de174a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "\n",
    "# Create the function to find all permutations (tất cả cặp phim mà user đã xem)\n",
    "def find_movie_pairs(x):\n",
    "    pairs = pd.DataFrame(list(permutations(x.values, 2)),\n",
    "                         columns=['movie_a', 'movie_b'])\n",
    "    return pairs\n",
    "\n",
    "# Apply the function to the title column and reset the index\n",
    "movie_combinations = user_ratings_df.groupby('userId')['title'].apply(find_movie_pairs).reset_index(drop=True)\n",
    "\n",
    "print(movie_combinations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621abd5-1577-40e3-ab13-907ade3de8b2",
   "metadata": {},
   "source": [
    "**Counting up the pairs** \n",
    "You can now create DataFrame of all the permutations of movies that have been watched by the same user. This is of limited use unless you can find which movies are most commonly paired. In this exercise, you will work with the *movie_combinations* DataFrame that you created in the last exercise (that has been loaded for you), and generate a new DataFrame containing the counts of occurrences of each of the pairs within.\n",
    "\n",
    "**Hint.** Find the number of times each pair of movies occurs and assign it to combination_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e117c-951a-4c6e-b345-e88f0268ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how often each item in movies_a occurs with the items in movies_b\n",
    "combination_counts = movie_combinations.groupby(['movie_a', 'movie_b']).size().reset_index(name='count')\n",
    "\n",
    "# Inspect the results\n",
    "print(combination_counts.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa799ea5-d227-4e06-8c81-0b45dce48d5f",
   "metadata": {},
   "source": [
    "**Making your first movie recommendations**\r\n",
    "\r\n",
    "Now that you have found the most commonly paired movies, you can make your first recommendations! While you are not taking in any information about the person watching, and do not even know any details about the movie, valuable recommendations can still be made by examining what groups of movies are watched by the same people. In this exercise, you will examine the movies often watched by the same people that watched Thor, and then use this data to give a recommendation to someone who just watched the movie. The DataFrame you generated in the last lesson, combination_counts_df, that contains counts of how often movies are watched together has been loaded for you.\r\n",
    "\r\n",
    "**Hint.** Order the *combination_counts_df* object from largest to smallest by the size column. Find the newly ordered movie frequencies for the movie Thor by subsetting ordered the *combination_counts_df* object where movie_a is Thor assign them to *thor_df* and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eee5a8-2a58-4736-9f28-d8843893630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort the counts from highest to lowest\n",
    "combination_counts_df.sort_values('size', ascending=False, inplace=True)\n",
    "\n",
    "# Find the movies most frequently watched by people who watched Thor\n",
    "thor_df = combination_counts_df[combination_counts_df['movie_a'] == 'Thor']\n",
    "\n",
    "# Plot the results\n",
    "thor_df.plot.bar(x=\"movie_b\", y=\"size\", legend=False, color='skyblue')\n",
    "plt.title(\"Movies most frequently watched with 'Thor'\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Movie\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
