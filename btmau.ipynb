{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d4e764-69fe-4cab-8e35-304d6201d96d",
   "metadata": {},
   "source": [
    "C√¢u 1. (2.5 ƒëi·ªÉm) ‚Äî Cold-start Recommendation\n",
    "\n",
    "T√≠nh t·ªïng s·ªë l∆∞·ª£t b√¨nh ch·ªçn v√† ƒëi·ªÉm trung b√¨nh c·ªßa t·ª´ng b√†i h√°t.\n",
    "\n",
    "T·∫°o c√¥ng th·ª©c ‚Äúƒë·ªô hot‚Äù:\n",
    "\n",
    "score = \\text{avg_rating} \\times \\log(\\text{num_votes})\n",
    "\n",
    "In ra top 5 b√†i h√°t n√™n g·ª£i √Ω cho user cold-start (ng∆∞·ªùi d√πng m·ªõi ch∆∞a c√≥ l·ªãch s·ª≠ nghe nh·∫°c).\n",
    "\n",
    "üëâ G·ª£i √Ω: d√πng groupby + agg trong Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3529c3-d294-4b26-8d33-2eb7787eb2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D·ªØ li·ªáu rating:\n",
      "   user_id  song_id  rating\n",
      "0        1      101       4\n",
      "1        1      102       5\n",
      "2        2      103       3\n",
      "3        2      104       4\n",
      "4        3      101       5\n",
      "5        3      105       2 \n",
      "\n",
      "üéß Top 5 b√†i h√°t n√™n nghe cho user cold-start:\n",
      "         soLuotBinhChon  soDiemTrungBinh     score\n",
      "song_id                                           \n",
      "101                   2              4.5  3.119162\n",
      "102                   1              5.0  0.000000\n",
      "103                   1              3.0  0.000000\n",
      "104                   1              4.0  0.000000\n",
      "105                   1              2.0  0.000000 \n",
      "\n",
      " D·ªØ li·ªáu b√†i h√°t:\n",
      "   song_id       title             genres\n",
      "0      101  Love Again         Pop|Ballad\n",
      "1      102     Thunder           Rock|Pop\n",
      "2      103     Skyline  Indie|Alternative\n",
      "3      104  Deep Ocean      Ambient|Chill\n",
      "4      105    Blaze Up         Rock|Metal \n",
      "\n",
      "üé• Top 10 b√†i h√°t t∆∞∆°ng ƒë·ªìng v·ªõi 'Love Again':\n",
      "   song_id       title                genres  tuongDong\n",
      "0      102     Thunder           {Pop, Rock}   0.333333\n",
      "1      103     Skyline  {Alternative, Indie}   0.000000\n",
      "2      104  Deep Ocean      {Chill, Ambient}   0.000000\n",
      "3      105    Blaze Up         {Metal, Rock}   0.000000 \n",
      "\n",
      "üìä Ma tr·∫≠n User‚ÄìItem:\n",
      "song_id  101  102  103  104  105\n",
      "user_id                         \n",
      "1        4.0  5.0  NaN  NaN  NaN\n",
      "2        NaN  NaN  3.0  4.0  NaN\n",
      "3        5.0  NaN  NaN  NaN  2.0 \n",
      "\n",
      " Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c User:\n",
      "user_id         1    2         3\n",
      "user_id                         \n",
      "1        1.000000  0.0  0.580015\n",
      "2        0.000000  1.0  0.000000\n",
      "3        0.580015  0.0  1.000000 \n",
      "\n",
      " Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c Item:\n",
      "song_id       101       102  103  104       105\n",
      "song_id                                        \n",
      "101      1.000000  0.624695  0.0  0.0  0.780869\n",
      "102      0.624695  1.000000  0.0  0.0  0.000000\n",
      "103      0.000000  0.000000  1.0  1.0  0.000000\n",
      "104      0.000000  0.000000  1.0  1.0  0.000000\n",
      "105      0.780869  0.000000  0.0  0.0  1.000000 \n",
      "\n",
      " G·ª£i √Ω b√†i h√°t cho t·ª´ng user:\n",
      "- User 1 n√™n nghe: [105, 103]\n",
      "- User 2 n√™n nghe: [101, 102]\n",
      "- User 3 n√™n nghe: [102, 103]\n",
      "\n",
      " Ho√†n th√†nh 3 ph·∫ßn: Cold-start, Content-based, Collaborative Filtering!\n"
     ]
    }
   ],
   "source": [
    "#  B√ÄI 1 ‚Äì COLD START RECOMMENDATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---- Gi·∫£ l·∫≠p d·ªØ li·ªáu rating\n",
    "data = {\n",
    "    'user_id': [1, 1, 2, 2, 3, 3],\n",
    "    'song_id': [101, 102, 103, 104, 101, 105],\n",
    "    'rating': [4, 5, 3, 4, 5, 2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\" D·ªØ li·ªáu rating:\")\n",
    "print(df, \"\\n\")\n",
    "\n",
    "# ---- T√≠nh s·ªë l∆∞·ª£t b√¨nh ch·ªçn v√† ƒëi·ªÉm trung b√¨nh\n",
    "baiHat = df.groupby('song_id').agg(\n",
    "    soLuotBinhChon=('rating', 'count'),\n",
    "    soDiemTrungBinh=('rating', 'mean')\n",
    ")\n",
    "baiHat['score'] = baiHat['soDiemTrungBinh'] * np.log(baiHat['soLuotBinhChon'])\n",
    "\n",
    "# ---- Top 5 b√†i h√°t n√™n nghe (user cold-start)\n",
    "top5 = baiHat.sort_values('score', ascending=False).head(5)\n",
    "print(\"üéß Top 5 b√†i h√°t n√™n nghe cho user cold-start:\")\n",
    "print(top5, \"\\n\")\n",
    "\n",
    "#  B√ÄI 2 ‚Äì CONTENT-BASED RECOMMENDATION\n",
    "\n",
    "songs = {\n",
    "    'song_id': [101, 102, 103, 104, 105],\n",
    "    'title': [\"Love Again\", \"Thunder\", \"Skyline\", \"Deep Ocean\", \"Blaze Up\"],\n",
    "    'genres': [\"Pop|Ballad\", \"Rock|Pop\", \"Indie|Alternative\", \"Ambient|Chill\", \"Rock|Metal\"]\n",
    "}\n",
    "df_songs = pd.DataFrame(songs)\n",
    "print(\" D·ªØ li·ªáu b√†i h√°t:\")\n",
    "print(df_songs, \"\\n\")\n",
    "\n",
    "# ---- Chuy·ªÉn th·ªÉ lo·∫°i sang set\n",
    "df_songs['genres'] = df_songs['genres'].apply(lambda x: set(x.split('|')))\n",
    "\n",
    "# ---- Ch·ªçn phim ƒë·∫ßu ti√™n l√†m v√≠ d·ª•\n",
    "phim1 = df_songs.iloc[0]\n",
    "\n",
    "tap_tuongDong = []\n",
    "for i, phim in df_songs.iterrows():\n",
    "    if phim['song_id'] != phim1['song_id']:\n",
    "        giao = len(phim1['genres'].intersection(phim['genres']))\n",
    "        hop = len(phim1['genres'].union(phim['genres']))\n",
    "        tuongDong = giao / hop if hop > 0 else 0\n",
    "        tap_tuongDong.append({\n",
    "            'song_id': phim['song_id'],\n",
    "            'title': phim['title'],\n",
    "            'genres': phim['genres'],\n",
    "            'tuongDong': tuongDong\n",
    "        })\n",
    "\n",
    "doTuongDong = pd.DataFrame(tap_tuongDong)\n",
    "doTuongDong_top = doTuongDong.sort_values('tuongDong', ascending=False).head(10)\n",
    "print(f\"üé• Top 10 b√†i h√°t t∆∞∆°ng ƒë·ªìng v·ªõi '{phim1['title']}':\")\n",
    "print(doTuongDong_top, \"\\n\")\n",
    "# üîπ B√ÄI 3 ‚Äì COLLABORATIVE FILTERING\n",
    "# ---- T·∫°o ma tr·∫≠n user‚Äìitem\n",
    "utility_matrix = df.pivot_table(index='user_id', columns='song_id', values='rating')\n",
    "print(\"üìä Ma tr·∫≠n User‚ÄìItem:\")\n",
    "print(utility_matrix, \"\\n\")\n",
    "\n",
    "# ---- T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c user\n",
    "user_similarity = pd.DataFrame(\n",
    "    cosine_similarity(utility_matrix.fillna(0)),\n",
    "    index=utility_matrix.index,\n",
    "    columns=utility_matrix.index\n",
    ")\n",
    "print(\" Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c User:\")\n",
    "print(user_similarity, \"\\n\")\n",
    "\n",
    "# ---- T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c item\n",
    "item_similarity = pd.DataFrame(\n",
    "    cosine_similarity(utility_matrix.fillna(0).T),\n",
    "    index=utility_matrix.columns,\n",
    "    columns=utility_matrix.columns\n",
    ")\n",
    "print(\" Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c Item:\")\n",
    "print(item_similarity, \"\\n\")\n",
    "\n",
    "# ---- G·ª£i √Ω b√†i h√°t cho t·ª´ng user d·ª±a tr√™n user t∆∞∆°ng t·ª±\n",
    "print(\" G·ª£i √Ω b√†i h√°t cho t·ª´ng user:\")\n",
    "for user in utility_matrix.index:\n",
    "    listened = utility_matrix.loc[user][utility_matrix.loc[user].notna()].index\n",
    "    not_listened = utility_matrix.columns.difference(listened)\n",
    "\n",
    "    similar_users = user_similarity[user].drop(user)\n",
    "    weights = similar_users / similar_users.sum()\n",
    "\n",
    "    pred_ratings = {}\n",
    "    for song in not_listened:\n",
    "        # üîß CH·ªà L·∫§Y rating C·ª¶A C√ÅC USER TRONG weights.index\n",
    "        other_ratings = utility_matrix.loc[weights.index, song]\n",
    "        pred = np.dot(weights, other_ratings.fillna(0))\n",
    "        pred_ratings[song] = pred\n",
    "\n",
    "    top_items = sorted(pred_ratings.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "    print(f\"- User {user} n√™n nghe:\", [i[0] for i in top_items])\n",
    "\n",
    "print(\"\\n Ho√†n th√†nh 3 ph·∫ßn: Cold-start, Content-based, Collaborative Filtering!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577414b8-7774-43f4-9d24-f2a293ef4c1b",
   "metadata": {},
   "source": [
    "Cold-start (top b√†i h√°t/phim n√™n g·ª£i √Ω cho user m·ªõi)\n",
    "\n",
    "üí° D√πng file ratings.csv trong MovieLens.\n",
    "\n",
    "G·ª£i √Ω ƒë·ªÅ thi:\n",
    "\n",
    "T·ª´ d·ªØ li·ªáu rating, h√£y ƒë·ªÅ xu·∫•t top 5 movies n√™n xem cho user m·ªõi (ch∆∞a c√≥ l·ªãch s·ª≠).\n",
    "G·ª£i √Ω: k·∫øt h·ª£p s·ªë l∆∞·ª£t rating v√† rating trung b√¨nh, t·∫°o c√¥ng th·ª©c:\n",
    "\n",
    "ùë†\n",
    "ùëê\n",
    "ùëú\n",
    "ùëü\n",
    "ùëí\n",
    "=\n",
    "ùëö\n",
    "ùëí\n",
    "ùëé\n",
    "ùëõ\n",
    "_\n",
    "ùëü\n",
    "ùëé\n",
    "ùë°\n",
    "ùëñ\n",
    "ùëõ\n",
    "ùëî\n",
    "√ó\n",
    "log\n",
    "‚Å°\n",
    "(\n",
    "ùëõ\n",
    "ùë¢\n",
    "ùëö\n",
    "_\n",
    "ùëü\n",
    "ùëé\n",
    "ùë°\n",
    "ùëñ\n",
    "ùëõ\n",
    "ùëî\n",
    "ùë†\n",
    ")\n",
    "score=mean_rating√ólog(num_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315dff18-75f9-471b-b741-db6945f00df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 phim n√™n g·ª£i √Ω cho user cold-start:\n",
      "         num_ratings  avg_rating      score\n",
      "movieId                                    \n",
      "318              317    4.429022  25.506303\n",
      "356              329    4.164134  24.135560\n",
      "296              307    4.197068  24.035972\n",
      "2571             278    4.192446  23.593498\n",
      "593              279    4.161290  23.433107\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('movie_lens/ratings.csv')\n",
    "\n",
    "movie_stats = df.groupby('movieId').agg(\n",
    "    num_ratings=('rating', 'count'),\n",
    "    avg_rating=('rating', 'mean')\n",
    ")\n",
    "movie_stats['score'] = movie_stats['avg_rating'] * np.log(movie_stats['num_ratings'])\n",
    "\n",
    "top5 = movie_stats.sort_values('score', ascending=False).head(5)\n",
    "print(\"Top 5 phim n√™n g·ª£i √Ω cho user cold-start:\")\n",
    "print(top5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e32dd1-cbaf-4ab3-b896-80464bb5331f",
   "metadata": {},
   "source": [
    "Content-Based Recommendation (theo th·ªÉ lo·∫°i phim)\n",
    "\n",
    "üí° D√πng file movies.csv, trong ƒë√≥ c√≥ c·ªôt genres.\n",
    "Th·∫ßy th∆∞·ªùng y√™u c·∫ßu t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard gi·ªØa 2 phim theo th·ªÉ lo·∫°i.\n",
    "\n",
    "G·ª£i √Ω ƒë·ªÅ thi:\n",
    "\n",
    "T·ª´ file movies.csv, ch·ªçn m·ªôt phim X v√† t√≠nh top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi X theo th·ªÉ lo·∫°i b·∫±ng ƒë·ªô ƒëo Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4caec4-a046-43eb-a94a-670fef0147fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 phim t∆∞∆°ng t·ª± 'Toy Story (1995)':\n",
      "      movieId                                              title  similarity\n",
      "2808     3754     Adventures of Rocky and Bullwinkle, The (2000)         1.0\n",
      "9429   166461                                       Moana (2016)         1.0\n",
      "7759    91355  Asterix and the Vikings (Ast√©rix et les Viking...         1.0\n",
      "6947    65577                     Tale of Despereaux, The (2008)         1.0\n",
      "6485    53121                             Shrek the Third (2007)         1.0\n",
      "3567     4886                              Monsters, Inc. (2001)         1.0\n",
      "1705     2294                                        Antz (1998)         1.0\n",
      "8218   103755                                       Turbo (2013)         1.0\n",
      "2999     4016                   Emperor's New Groove, The (2000)         1.0\n",
      "8926   136016                           The Good Dinosaur (2015)         1.0\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('movie_lens/movies.csv')\n",
    "movies['genres'] = movies['genres'].apply(lambda x: set(x.split('|')))\n",
    "\n",
    "film_x = movies.iloc[0]  # ch·ªçn phim ƒë·∫ßu ti√™n\n",
    "\n",
    "similarity_list = []\n",
    "for i, film in movies.iterrows():\n",
    "    if film['movieId'] != film_x['movieId']:\n",
    "        inter = len(film_x['genres'].intersection(film['genres']))\n",
    "        union = len(film_x['genres'].union(film['genres']))\n",
    "        jaccard = inter / union if union > 0 else 0\n",
    "        similarity_list.append({\n",
    "            'movieId': film['movieId'],\n",
    "            'title': film['title'],\n",
    "            'similarity': jaccard\n",
    "        })\n",
    "\n",
    "result = pd.DataFrame(similarity_list).sort_values('similarity', ascending=False)\n",
    "print(f\"Top 10 phim t∆∞∆°ng t·ª± '{film_x['title']}':\")\n",
    "print(result.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a0795-ca4a-4920-bf21-cd2c9b7dc15c",
   "metadata": {},
   "source": [
    "Collaborative Filtering (l·ªçc c·ªông t√°c)\n",
    "\n",
    "üí° D√πng file ratings.csv ‚Üí pivot th√†nh ma tr·∫≠n User √ó Movie.\n",
    "Sau ƒë√≥ t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa user ho·∫∑c gi·ªØa item.\n",
    "\n",
    "G·ª£i √Ω ƒë·ªÅ thi:\n",
    "\n",
    "T√≠nh ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c user (user-based CF) v√† gi·ªØa c√°c item (item-based CF).\n",
    "V·ªõi m·ªói user, g·ª£i √Ω 2 phim h·ªç ch∆∞a xem d·ª±a tr√™n user t∆∞∆°ng t·ª±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c4821b-1eb6-4dae-8cf6-c1802d4fc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix:\n",
      "userId       1         2        3         4         5         6         7    \\\n",
      "userId                                                                        \n",
      "1       1.000000  0.027283  0.05972  0.194395  0.129080  0.128152  0.158744   \n",
      "2       0.027283  1.000000  0.00000  0.003726  0.016614  0.025333  0.027585   \n",
      "3       0.059720  0.000000  1.00000  0.002251  0.005020  0.003936  0.000000   \n",
      "\n",
      "userId       8         9         10   ...       601       602       603  \\\n",
      "userId                                ...                                 \n",
      "1       0.136968  0.064263  0.016875  ...  0.080554  0.164455  0.221486   \n",
      "2       0.027257  0.000000  0.067445  ...  0.202671  0.016866  0.011997   \n",
      "3       0.004941  0.000000  0.000000  ...  0.005048  0.004892  0.024992   \n",
      "\n",
      "userId       604       605       606       607       608       609       610  \n",
      "userId                                                                        \n",
      "1       0.070669  0.153625  0.164191  0.269389  0.291097  0.093572  0.145321  \n",
      "2       0.000000  0.000000  0.028429  0.012948  0.046211  0.027565  0.102427  \n",
      "3       0.000000  0.010694  0.012993  0.019247  0.021128  0.000000  0.032119  \n",
      "\n",
      "[3 rows x 610 columns]\n",
      "Item similarity matrix:\n",
      "movieId    1         2         3         4         5         6         7       \\\n",
      "movieId                                                                         \n",
      "1        1.000000  0.410562  0.296917  0.035573  0.308762  0.376316  0.277491   \n",
      "2        0.410562  1.000000  0.282438  0.106415  0.287795  0.297009  0.228576   \n",
      "3        0.296917  0.282438  1.000000  0.092406  0.417802  0.284257  0.402831   \n",
      "\n",
      "movieId    8         9         10      ...  193565  193567  193571  193573  \\\n",
      "movieId                                ...                                   \n",
      "1        0.131629  0.232586  0.395573  ...     0.0     0.0     0.0     0.0   \n",
      "2        0.172498  0.044835  0.417693  ...     0.0     0.0     0.0     0.0   \n",
      "3        0.313434  0.304840  0.242954  ...     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  193579  193581  193583  193585  193587  193609  \n",
      "movieId                                                  \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[3 rows x 9724 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ratings = pd.read_csv('movie_lens/ratings.csv')\n",
    "pivot = ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# ƒê·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa user\n",
    "user_sim = pd.DataFrame(\n",
    "    cosine_similarity(pivot.fillna(0)),\n",
    "    index=pivot.index, columns=pivot.index\n",
    ")\n",
    "\n",
    "# ƒê·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa item\n",
    "item_sim = pd.DataFrame(\n",
    "    cosine_similarity(pivot.fillna(0).T),\n",
    "    index=pivot.columns, columns=pivot.columns\n",
    ")\n",
    "\n",
    "print(\"User similarity matrix:\")\n",
    "print(user_sim.head(3))\n",
    "\n",
    "print(\"Item similarity matrix:\")\n",
    "print(item_sim.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88dca8-fad7-40ca-83e5-b77264457905",
   "metadata": {},
   "source": [
    "C√≥ th·ªÉ th√™m (d·ª± ƒëo√°n missing rating)\n",
    "\n",
    "Th·∫ßy c√≥ th·ªÉ h·ªèi ki·ªÉu:\n",
    "\n",
    "‚ÄúD·ª± ƒëo√°n gi√° tr·ªã rating c√≤n thi·∫øu b·∫±ng Pearson / Cosine similarity‚Äù.\n",
    "\n",
    "üìò G·ª£i √Ω:\n",
    "\n",
    "V·ªõi Pearson, chu·∫©n h√≥a m·ªói h√†ng (tr·ª´ ƒëi trung b√¨nh t·ª´ng user).\n",
    "\n",
    "V·ªõi Cosine, ch·ªâ c·∫ßn ƒëi·ªÅn NaN = 0 r·ªìi t√≠nh b·∫±ng cosine_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad298916-0cd0-48ba-805b-dde781495e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ª± ƒëo√°n rating U1-I3: 3.38\n"
     ]
    }
   ],
   "source": [
    "# 1. User-based Collaborative Filtering\n",
    "\n",
    "#√ù t∆∞·ªüng: d·ª± ƒëo√°n rating c·ªßa user d·ª±a tr√™n c√°c user t∆∞∆°ng t·ª±.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ma tr·∫≠n user-item\n",
    "ratings = pd.DataFrame({\n",
    "    'I1': [4, 5, 2, np.nan],\n",
    "    'I2': [3, 2, 5, 3],\n",
    "    'I3': [np.nan, 2, 4, 3],\n",
    "    'I4': [4, 5, 1, 2]\n",
    "}, index=['U1', 'U2', 'U3', 'U4'])\n",
    "\n",
    "# T√≠nh cosine similarity gi·ªØa users\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_sim = pd.DataFrame(cosine_similarity(ratings.fillna(0)),\n",
    "                        index=ratings.index, columns=ratings.index)\n",
    "\n",
    "# D·ª± ƒëo√°n rating thi·∫øu (v√≠ d·ª• U1, I3)\n",
    "target_user, target_item = 'U1', 'I3'\n",
    "neighbors = user_sim[target_user].drop(target_user)\n",
    "\n",
    "# L·∫•y user c√≥ rating cho I3\n",
    "valid_users = ratings[~ratings[target_item].isna()].index\n",
    "numerator, denominator = 0, 0\n",
    "mean_u = ratings.loc[target_user].mean()\n",
    "\n",
    "for v in valid_users:\n",
    "    sim = user_sim.loc[target_user, v]\n",
    "    mean_v = ratings.loc[v].mean()\n",
    "    numerator += sim * (ratings.loc[v, target_item] - mean_v)\n",
    "    denominator += abs(sim)\n",
    "\n",
    "pred = mean_u + numerator / denominator\n",
    "print(f\"D·ª± ƒëo√°n rating {target_user}-{target_item}: {pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ec57b3-6944-404e-baae-e0a9d7e3f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ª± ƒëo√°n rating U1-I3: 3.54\n"
     ]
    }
   ],
   "source": [
    "#tem-based Collaborative Filtering\n",
    "\n",
    "#√ù t∆∞·ªüng: d·ª± ƒëo√°n rating c·ªßa user cho item d·ª±a v√†o c√°c item t∆∞∆°ng t·ª± m√† user ƒë√£ ƒë√°nh gi√°.\n",
    "item_sim = pd.DataFrame(cosine_similarity(ratings.fillna(0).T),\n",
    "                        index=ratings.columns, columns=ratings.columns)\n",
    "\n",
    "target_user, target_item = 'U1', 'I3'\n",
    "rated_items = ratings.loc[target_user].dropna()\n",
    "\n",
    "numerator, denominator = 0, 0\n",
    "for j in rated_items.index:\n",
    "    sim = item_sim.loc[target_item, j]\n",
    "    numerator += sim * ratings.loc[target_user, j]\n",
    "    denominator += abs(sim)\n",
    "\n",
    "pred = numerator / denominator\n",
    "print(f\"D·ª± ƒëo√°n rating {target_user}-{target_item}: {pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b48099-1ab0-4f8c-b3ab-a30a76960a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê·ªô t∆∞∆°ng ƒë·ªìng Jaccard: 0.5\n"
     ]
    }
   ],
   "source": [
    "#t√≠nh jaccard \n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "item1 = [1, 0, 1, 1, 0]\n",
    "item2 = [1, 1, 0, 1, 0]\n",
    "sim = jaccard_score(item1, item2)\n",
    "print(\"ƒê·ªô t∆∞∆°ng ƒë·ªìng Jaccard:\", sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2531a3-fb47-43c3-b3e1-72b586db6480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c item:\n",
      " [[1.         0.19297924 0.4078538  0.        ]\n",
      " [0.19297924 1.         0.         0.        ]\n",
      " [0.4078538  0.         1.         0.        ]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Content-based b·∫±ng TF-IDF (vƒÉn b·∫£n m√¥ t·∫£)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docs = [\n",
    "    \"AI machine learning data\",\n",
    "    \"deep learning neural network\",\n",
    "    \"AI data science project\",\n",
    "    \"web development html css\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(docs)\n",
    "sim = cosine_similarity(tfidf)\n",
    "\n",
    "print(\"Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c item:\\n\", sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed543a0-c1a7-4ae6-aaaf-3c5358aa98c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      I1    I2    I3    I4\n",
      "U1  4.14  2.15  0.89  4.11\n",
      "U2  4.90  2.73  1.23  4.88\n",
      "U3  1.41  4.81  4.16  1.66\n",
      "U4  0.87  3.23  2.82  1.04\n"
     ]
    }
   ],
   "source": [
    "#D·ª± ƒëo√°n rating b·∫±ng SVD (d·∫°ng c∆° b·∫£n)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "R = ratings.fillna(0).values\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "U = svd.fit_transform(R)\n",
    "V = svd.components_\n",
    "\n",
    "pred = np.dot(U, V)\n",
    "pred_df = pd.DataFrame(pred, index=ratings.index, columns=ratings.columns)\n",
    "print(pred_df.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a1d34a-85ef-4565-85ff-4ffbf5f69d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ª± ƒëo√°n rating: 3.77\n"
     ]
    }
   ],
   "source": [
    "#üß© 6. D·ª± ƒëo√°n missing value (b√†i cold-start nh·ªè)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'I1': [4, 3, 2],\n",
    "    'I2': [3, 1, 3],\n",
    "    'I3': [np.nan, 2, 3],\n",
    "    'I4': [4, 3, 2]\n",
    "}, index=['U1', 'U2', 'U3'])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = pd.DataFrame(cosine_similarity(data.fillna(0)),\n",
    "                   index=data.index, columns=data.index)\n",
    "\n",
    "target_user, target_item = 'U1', 'I3'\n",
    "mean_u = data.loc[target_user].mean()\n",
    "numerator, denominator = 0, 0\n",
    "\n",
    "for v in data.index:\n",
    "    if v != target_user and not np.isnan(data.loc[v, target_item]):\n",
    "        sim_uv = sim.loc[target_user, v]\n",
    "        mean_v = data.loc[v].mean()\n",
    "        numerator += sim_uv * (data.loc[v, target_item] - mean_v)\n",
    "        denominator += abs(sim_uv)\n",
    "\n",
    "pred = mean_u + numerator / denominator\n",
    "print(\"D·ª± ƒëo√°n rating:\", round(pred, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09320268-cb72-467b-826d-c8e6693f6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# B√ÄI 3: L·ªåC C·ªòNG T√ÅC (COLLABORATIVE FILTERING)\n",
    "# S·ª≠ d·ª•ng kNN (user-based & item-based)\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv('data.csv', names=['userId', 'songId', 'rating'])\n",
    "df = df.dropna(subset=['userId', 'songId', 'rating'])\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "df = df.groupby(['userId', 'songId'])['rating'].mean().reset_index()\n",
    "\n",
    "# -------------------------------\n",
    "# T·∫°o ma tr·∫≠n user-item\n",
    "# -------------------------------\n",
    "pivot = df.pivot_table(index='userId', columns='songId', values='rating').fill_value=0\n",
    "pivot = df.pivot_table(index='userId', columns='songId', values='rating').fillna(0)\n",
    "\n",
    "print(\"üìä Ma tr·∫≠n user-item:\")\n",
    "display(pivot.head())\n",
    "\n",
    "# ============================================\n",
    "# 1Ô∏è‚É£ USER-BASED COLLABORATIVE FILTERING (kNN)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== USER-BASED CF ===\")\n",
    "\n",
    "# M√¥ h√¨nh kNN\n",
    "model_user = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_user.fit(pivot)\n",
    "\n",
    "# Ch·ªçn 1 user b·∫•t k·ª≥ (v√≠ d·ª• user ƒë·∫ßu ti√™n)\n",
    "target_user = pivot.index[0]\n",
    "print(f\"üéØ G·ª£i √Ω cho user: {target_user}\")\n",
    "\n",
    "# T√¨m k user t∆∞∆°ng t·ª± nh·∫•t\n",
    "distances, indices = model_user.kneighbors(pivot.loc[[target_user]], n_neighbors=6)\n",
    "\n",
    "# In ra top 5 user t∆∞∆°ng t·ª±\n",
    "print(\"\\nüë• Top 5 user t∆∞∆°ng t·ª±:\")\n",
    "for i in range(1, 6):\n",
    "    print(f\"{i}. User: {pivot.index[indices.flatten()[i]]}, Similarity: {1 - distances.flatten()[i]:.3f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# G·ª£i √Ω b√†i h√°t cho user\n",
    "# -------------------------------\n",
    "# T√≠nh trung b√¨nh rating c·ªßa c√°c user t∆∞∆°ng t·ª± ƒë·ªÉ ƒë·ªÅ xu·∫•t b√†i ch∆∞a nghe\n",
    "similar_users = pivot.index[indices.flatten()[1:6]]\n",
    "mean_ratings = pivot.loc[similar_users].mean().sort_values(ascending=False)\n",
    "recommended_songs_user = mean_ratings.head(5)\n",
    "\n",
    "print(\"\\nüéµ G·ª£i √Ω b√†i h√°t (theo user-based CF):\")\n",
    "print(recommended_songs_user)\n",
    "\n",
    "# ============================================\n",
    "# 2Ô∏è‚É£ ITEM-BASED COLLABORATIVE FILTERING (kNN)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n=== ITEM-BASED CF ===\")\n",
    "\n",
    "# Chuy·ªÉn v·ªã ƒë·ªÉ c√°c c·ªôt l√† user, h√†ng l√† b√†i h√°t\n",
    "pivot_item = pivot.T\n",
    "\n",
    "# M√¥ h√¨nh kNN\n",
    "model_item = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_item.fit(pivot_item)\n",
    "\n",
    "# Ch·ªçn 1 b√†i h√°t b·∫•t k·ª≥ (v√≠ d·ª• b√†i ƒë·∫ßu ti√™n)\n",
    "target_song = pivot_item.index[0]\n",
    "print(f\"üéØ G·ª£i √Ω b√†i h√°t t∆∞∆°ng t·ª± v·ªõi: {target_song}\")\n",
    "\n",
    "# T√¨m k b√†i h√°t t∆∞∆°ng t·ª±\n",
    "distances_item, indices_item = model_item.kneighbors(pivot_item.loc[[target_song]], n_neighbors=6)\n",
    "\n",
    "print(\"\\nüéß Top 5 b√†i h√°t t∆∞∆°ng t·ª± (item-based):\")\n",
    "for i in range(1, 6):\n",
    "    print(f\"{i}. B√†i h√°t: {pivot_item.index[indices_item.flatten()[i]]}, Similarity: {1 - distances_item.flatten()[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab165391-885d-4e4e-a583-c3c529e83921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning: (400, 3)\n",
      "  user item  rating\n",
      "0    1   18     5.0\n",
      "1   10   13     4.0\n",
      "2   10   14     5.0\n",
      "3   10   15     2.0\n",
      "4   10   16     2.0\n",
      "User-Item matrix shape: (81, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>2</th>\n",
       "      <th>20</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "item    1   10   11   12   13        14        15   16   17   18   19    2  \\\n",
       "user                                                                         \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  5.0  0.0  0.0   \n",
       "10    0.0  0.0  0.0  0.0  4.0  5.000000  2.000000  2.0  0.0  0.0  3.0  2.0   \n",
       "100   0.0  0.0  3.0  0.0  0.0  0.000000  5.000000  2.0  3.0  0.0  0.0  0.0   \n",
       "11    0.0  0.0  0.0  3.5  2.0  0.000000  1.000000  4.5  4.0  0.0  0.0  0.0   \n",
       "12    0.0  3.0  0.0  1.0  0.0  2.333333  3.333333  0.0  0.0  3.0  0.0  0.0   \n",
       "\n",
       "item   20    3    4    5    6    7    8    9  \n",
       "user                                          \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10    0.0  0.0  0.0  2.0  0.0  0.0  0.0  5.0  \n",
       "100   0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  \n",
       "11    0.0  5.0  2.0  3.0  3.0  3.0  0.0  3.5  \n",
       "12    0.0  0.0  0.0  1.0  2.0  0.0  1.0  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for user 1:\n",
      "  item  weighted_sum  sim_sum  score\n",
      "0    1           0.0      0.0    NaN\n",
      "1   10           0.0      0.0    NaN\n",
      "2   11           0.0      0.0    NaN\n",
      "3   12           0.0      0.0    NaN\n",
      "4   13           0.0      0.0    NaN\n",
      "5   14           0.0      0.0    NaN\n",
      "6   15           0.0      0.0    NaN\n",
      "7   16           0.0      0.0    NaN\n",
      "8   17           0.0      0.0    NaN\n",
      "9   19           0.0      0.0    NaN\n",
      "\n",
      "Items similar to 1:\n",
      "  item  similarity\n",
      "0   20    0.260248\n",
      "1    9    0.181275\n",
      "2   14    0.032383\n",
      "3   17    0.026995\n",
      "4   18    0.025686\n",
      "\n",
      "Saved pivot matrices to CSV.\n"
     ]
    }
   ],
   "source": [
    "# ====== IMPORTS ======\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ====== 0. LOAD DATA (thay ƒë∆∞·ªùng d·∫´n n·∫øu c·∫ßn) ======\n",
    "# H·ªó tr·ª£ c·∫£ 2 d·∫°ng: ('user','title','rating') ho·∫∑c ('userId','songId','rating')\n",
    "df = pd.read_csv('data.csv', names=['user', 'title', 'rating'])  # n·∫øu file ƒë√£ c√≥ header, b·ªè names=\n",
    "# N·∫øu file c·ªßa b·∫°n c√≥ header 'userId','songId','rating', d√πng:\n",
    "# df = pd.read_csv('data.csv')\n",
    "\n",
    "# N·∫øu c·ªôt t√™n kh√°c, normalize t√™n c·ªôt ƒë·ªÉ th·ªëng nh·∫•t\n",
    "cols = [c.lower().strip() for c in df.columns]\n",
    "rename_map = {}\n",
    "if 'user' in cols:\n",
    "    rename_map[df.columns[cols.index('user')]] = 'user'\n",
    "elif 'userid' in cols:\n",
    "    rename_map[df.columns[cols.index('userid')]] = 'user'\n",
    "if 'title' in cols:\n",
    "    rename_map[df.columns[cols.index('title')]] = 'item'\n",
    "elif 'songid' in cols:\n",
    "    rename_map[df.columns[cols.index('songid')]] = 'item'\n",
    "if 'rating' in cols:\n",
    "    rename_map[df.columns[cols.index('rating')]] = 'rating'\n",
    "\n",
    "df = df.rename(columns=rename_map)[['user','item','rating']]\n",
    "\n",
    "# ====== 1. TI·ªÄN X·ª¨ L√ù (CLEANING) ======\n",
    "# 1.1 drop NA\n",
    "df = df.dropna(subset=['user','item','rating'])\n",
    "\n",
    "# 1.2 √©p ki·ªÉu, strip\n",
    "df['user'] = df['user'].astype(str).str.strip()\n",
    "df['item'] = df['item'].astype(str).str.strip()\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "# 1.3 lo·∫°i rating b·∫•t th∆∞·ªùng (n·∫øu bi·∫øt scale, v√≠ d·ª• 1-5)\n",
    "df = df[(df['rating'] >= 1) & (df['rating'] <= 5)]\n",
    "\n",
    "# 1.4 n·∫øu m·ªôt user rate 1 item nhi·ªÅu l·∫ßn, l·∫•y trung b√¨nh (ho·∫∑c latest tu·ª≥ √Ω)\n",
    "df = df.groupby(['user','item'])['rating'].mean().reset_index()\n",
    "\n",
    "print(\"Data after cleaning:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ====== 2. PIVOT: t·∫°o user-item matrix ======\n",
    "# M·ªói h√†ng = 1 user, m·ªói c·ªôt = 1 item\n",
    "user_item = df.pivot(index='user', columns='item', values='rating')\n",
    "\n",
    "# Th√¥ng th∆∞·ªùng ƒëi·ªÅn NaN b·∫±ng 0 cho thu·∫≠t to√°n kNN cosine; \n",
    "# nh∆∞ng ch√∫ √Ω: 0 c√≥ th·ªÉ mang √Ω nghƒ©a \"kh√¥ng ƒë√°nh gi√°\" ‚Äî t√πy ch·ªçn kh√°c l√† fill b·∫±ng user mean khi c·∫ßn\n",
    "user_item_fill0 = user_item.fillna(0)\n",
    "\n",
    "print(\"User-Item matrix shape:\", user_item_fill0.shape)\n",
    "display(user_item_fill0.head())\n",
    "\n",
    "# ====== 3. OPTION: MEAN-CENTERING (kh·ª≠ bias ng∆∞·ªùi d√πng) ======\n",
    "# Khi d√πng cosine, nhi·ªÅu t√†i li·ªáu khuy·∫øn kh√≠ch mean-centering (rating - user_mean)\n",
    "user_means = user_item.mean(axis=1)                      # mean tr√™n h√†ng (user)\n",
    "user_item_centered = user_item.sub(user_means, axis=0)   # NaN preserved\n",
    "user_item_centered_filled = user_item_centered.fillna(0) # ƒëi·ªÅn 0 cho ph·∫ßn ch∆∞a rate (t·ª©c l√† trung h√≤a)\n",
    "\n",
    "# B·∫°n c√≥ th·ªÉ d√πng user_item_fill0 (raw) ho·∫∑c user_item_centered_filled (centered)\n",
    "MATRIX = user_item_centered_filled   # ch·ªçn ma tr·∫≠n ƒë·ªÉ train kNN\n",
    "\n",
    "# ====== 4. USER-BASED kNN: t√¨m ng∆∞·ªùi t∆∞∆°ng t·ª± & g·ª£i √Ω ======\n",
    "def user_based_recommend(user_id, matrix=MATRIX, df_original=df, k=5, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ top-n g·ª£i √Ω cho user_id d·ª±a tr√™n user-based kNN.\n",
    "    - matrix: DataFrame user x item (ƒë√£ fillna)\n",
    "    - df_original: original ratings dataframe ƒë·ªÉ l·ªçc items ƒë√£ c√≥ c·ªßa user\n",
    "    \"\"\"\n",
    "    if user_id not in matrix.index:\n",
    "        raise ValueError(\"User kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.\")\n",
    "\n",
    "    model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    model.fit(matrix.values)\n",
    "\n",
    "    user_vec = matrix.loc[[user_id]].values\n",
    "    distances, indices = model.kneighbors(user_vec, n_neighbors=k+1)  # +1 v√¨ ch√≠nh user s·∫Ω l√† neighbor th·ª© 0\n",
    "\n",
    "    similar_user_idxs = indices.flatten()[1:]     # b·ªè ch√≠nh user\n",
    "    similar_users = matrix.index[similar_user_idxs]\n",
    "    sims = 1 - distances.flatten()[1:]            # similarity = 1 - cosine_distance\n",
    "\n",
    "    # L·∫•y c√°c item m√† similar users ƒë√°nh gi√°, t√≠nh weighted score\n",
    "    sim_df = pd.DataFrame({'user': similar_users, 'sim': sims})\n",
    "    # merge ƒë·ªÉ c√≥ ratings\n",
    "    merged = sim_df.merge(df_original, on='user')   # (user, sim) + (user,item,rating)\n",
    "    # lo·∫°i b·ªè item user ƒë√£ c√≥\n",
    "    items_already = set(df_original[df_original['user']==user_id]['item'])\n",
    "    candidates = merged[~merged['item'].isin(items_already)].copy()\n",
    "\n",
    "    # weighted score: sim * rating, r·ªìi sum / sum(sim)\n",
    "    candidates['weighted'] = candidates['sim'] * candidates['rating']\n",
    "    score = candidates.groupby('item').agg(weighted_sum=('weighted','sum'), sim_sum=('sim','sum'))\n",
    "    score['score'] = score['weighted_sum'] / score['sim_sum']\n",
    "    score = score.sort_values('score', ascending=False).head(n_recommendations)\n",
    "    return score.reset_index()\n",
    "\n",
    "# V√≠ d·ª•: g·ª£i √Ω cho user ƒë·∫ßu ti√™n\n",
    "example_user = MATRIX.index[0]\n",
    "rec_for_user = user_based_recommend(example_user, k=5, n_recommendations=10)\n",
    "print(f\"\\nRecommendations for user {example_user}:\")\n",
    "print(rec_for_user)\n",
    "\n",
    "# ====== 5. ITEM-BASED kNN: t√¨m item t∆∞∆°ng t·ª± ======\n",
    "def item_based_recommend(item_id, matrix=MATRIX, df_original=df, k=10, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ top-n item t∆∞∆°ng t·ª± cho item_id (item-based kNN).\n",
    "    - matrix: user x item (centered and filled) -> transpose inside\n",
    "    \"\"\"\n",
    "    if item_id not in matrix.columns:\n",
    "        raise ValueError(\"Item kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.\")\n",
    "\n",
    "    item_matrix = matrix.T  # now rows = items, cols = users\n",
    "    model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    model.fit(item_matrix.values)\n",
    "\n",
    "    item_vec = item_matrix.loc[[item_id]].values\n",
    "    distances, indices = model.kneighbors(item_vec, n_neighbors=k+1)\n",
    "\n",
    "    neighbor_idxs = indices.flatten()[1:]\n",
    "    neighbors = item_matrix.index[neighbor_idxs]\n",
    "    sims = 1 - distances.flatten()[1:]\n",
    "\n",
    "    out = pd.DataFrame({\"item\": neighbors, \"similarity\": sims})\n",
    "    return out.head(n_neighbors)\n",
    "\n",
    "# V√≠ d·ª•: t∆∞∆°ng t·ª± v·ªõi item ƒë·∫ßu ti√™n\n",
    "example_item = MATRIX.columns[0]\n",
    "print(f\"\\nItems similar to {example_item}:\")\n",
    "print(item_based_recommend(example_item, k=10, n_neighbors=5))\n",
    "\n",
    "# ====== 6. L∆ØU & NOTE ======\n",
    "# L∆∞u ma tr·∫≠n (n·∫øu c·∫ßn)\n",
    "user_item_fill0.to_csv('user_item_fill0.csv')\n",
    "user_item_centered_filled.to_csv('user_item_centered.csv')\n",
    "print(\"\\nSaved pivot matrices to CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3606e-df01-42be-9590-508d1dd4488a",
   "metadata": {},
   "source": [
    "hu·∫≠t to√°n l·ªçc c·ªông t√°c (Collaborative Filtering) l√† m·ªôt k·ªπ thu·∫≠t g·ª£i √Ω d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng gi·ªØa ng∆∞·ªùi d√πng ho·∫∑c gi·ªØa c√°c s·∫£n ph·∫©m. Trong b√†i, ch√∫ng em s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p k-Nearest Neighbors (kNN) ƒë·ªÉ t√¨m c√°c ng∆∞·ªùi d√πng ho·∫∑c b√†i h√°t c√≥ h√†nh vi t∆∞∆°ng t·ª± v√† t·ª´ ƒë√≥ ƒë·ªÅ xu·∫•t nh·ªØng b√†i h√°t m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ y√™u th√≠ch.‚Äù"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
